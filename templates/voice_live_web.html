<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Live Web - Real-time Voice Chat</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.0.1/socket.io.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            min-height: 100vh;
        }
        
        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 8px 32px 0 rgba(31, 38, 135, 0.37);
            border: 1px solid rgba(255, 255, 255, 0.18);
        }
        
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .status {
            text-align: center;
            padding: 15px;
            margin: 20px 0;
            border-radius: 10px;
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .status.connected {
            background: rgba(76, 175, 80, 0.3);
            border: 1px solid #4CAF50;
        }
        
        .status.disconnected {
            background: rgba(244, 67, 54, 0.3);
            border: 1px solid #f44336;
        }
        
        .status.listening {
            background: rgba(255, 193, 7, 0.3);
            border: 1px solid #FFC107;
            animation: pulse 1.5s infinite;
        }
        
        .status.processing {
            background: rgba(156, 39, 176, 0.3);
            border: 1px solid #9C27B0;
            animation: pulse 1.5s infinite;
        }
        
        .agent-status {
            text-align: center;
            padding: 15px;
            margin: 20px 0;
            border-radius: 10px;
            background: rgba(33, 150, 243, 0.2);
            border: 1px solid #2196F3;
            transition: all 0.3s ease;
        }
        
        .agent-status.thinking {
            background: rgba(156, 39, 176, 0.2);
            border: 1px solid #9C27B0;
            animation: pulse 1.5s infinite;
        }
        
        .agent-indicator {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
            font-weight: bold;
        }
        
        .agent-icon {
            font-size: 1.5em;
        }
        
        .thinking-dots {
            display: inline-flex;
            gap: 3px;
        }
        
        .thinking-dots span {
            width: 6px;
            height: 6px;
            background: #9C27B0;
            border-radius: 50%;
            animation: thinking 1.5s infinite;
        }
        
        .thinking-dots span:nth-child(2) {
            animation-delay: 0.2s;
        }
        
        .thinking-dots span:nth-child(3) {
            animation-delay: 0.4s;
        }
        
        @keyframes thinking {
            0%, 60%, 100% { transform: scale(1); opacity: 0.7; }
            30% { transform: scale(1.2); opacity: 1; }
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        
        .controls {
            text-align: center;
            margin: 30px 0;
        }
        
        button {
            background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
            border: none;
            color: white;
            padding: 15px 30px;
            margin: 10px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 1.1em;
            font-weight: bold;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px 0 rgba(31, 38, 135, 0.2);
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px 0 rgba(31, 38, 135, 0.4);
        }
        
        button:disabled {
            background: #666;
            cursor: not-allowed;
            transform: none;
        }
        
        #pauseButton {
            background: linear-gradient(45deg, #FF9800, #FF5722);
        }
        
        #resumeButton {
            background: linear-gradient(45deg, #4CAF50, #8BC34A);
        }
        
        #microphoneButton {
            font-size: 2em;
            width: 80px;
            height: 80px;
            border-radius: 50%;
            margin: 20px;
        }
        
        #microphoneButton.recording {
            animation: pulse 1s infinite;
            background: linear-gradient(45deg, #f44336, #FF5722);
        }
        
        #microphoneButton.disabled {
            background: linear-gradient(45deg, #9E9E9E, #757575);
            cursor: not-allowed;
        }
        
        .microphone-instructions {
            font-size: 0.9em;
            color: rgba(255, 255, 255, 0.8);
            margin-top: 10px;
            text-align: center;
        }
        
        .chat-container {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
    /* Added: two-column layout and agent transcript panel */
    .conversation-layout { display: flex; flex-direction: row; gap: 20px; align-items: stretch; }
    .left-pane { flex: 2 1 60%; display: flex; flex-direction: column; }
    .right-pane { flex: 1 1 40%; display: flex; flex-direction: column; background: rgba(255,255,255,0.06); border: 1px solid rgba(255,255,255,0.12); border-radius: 15px; padding: 16px 14px 12px 16px; margin-top: 20px; position: relative; max-height: 400px; }
    .agent-transcript-header { font-weight:600; margin-bottom:8px; display:flex; justify-content:space-between; align-items:center; font-size:0.95em; letter-spacing:.5px; }
    .agent-transcript-list { overflow-y:auto; flex:1 1 auto; padding-right:6px; scrollbar-width:thin; }
    .agent-line { font-size:0.88em; line-height:1.25em; background:linear-gradient(135deg,#f093fb33 0%, #f5576c33 100%); border-left:3px solid #f5576c; padding:6px 10px; margin-bottom:8px; border-radius:8px; word-break:break-word; animation:fadeIn 0.4s ease; }
    .agent-line time { display:block; font-size:0.65em; opacity:0.65; margin-top:4px; }
    .clear-transcript-btn { background:#9C27B0; padding:4px 10px; margin:0; font-size:0.7em; border-radius:20px; box-shadow:none; }
    .clear-transcript-btn:hover { box-shadow:0 0 6px rgba(255,255,255,0.3); }
        
        .message {
            margin: 15px 0;
            padding: 12px 18px;
            border-radius: 18px;
            max-width: 80%;
            word-wrap: break-word;
            animation: fadeIn 0.5s ease;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        .user-message {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            margin-left: auto;
            text-align: right;
        }
        
        .agent-message {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            margin-right: auto;
        }
        
        .transcript {
            background: rgba(255, 255, 255, 0.1);
            font-style: italic;
            border-left: 3px solid #4ECDC4;
            padding-left: 15px;
        }
        
        .error {
            background: rgba(244, 67, 54, 0.3);
            border: 1px solid #f44336;
            color: #ffcdd2;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
        }
        
        .audio-visualizer {
            height: 60px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 30px;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }
        
        .visualizer-bar {
            width: 4px;
            background: linear-gradient(to top, #4ECDC4, #44A08D);
            margin: 0 2px;
            border-radius: 2px;
            transition: height 0.1s ease;
        }
        
        #microphoneButton {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            font-size: 2em;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        #microphoneButton.recording {
            background: linear-gradient(45deg, #FF6B6B, #FF8E53);
            animation: pulse 1s infinite;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎤 Voice Live Chat</h1>
        
        <div id="status" class="status disconnected">
            Disconnected - Click "Start Session" to begin
        </div>
        
        <div id="agentStatus" class="agent-status" style="display: none;">
            <div class="agent-indicator">
                <span class="agent-icon">🤖</span>
                <span id="agentStatusText">Agent Ready</span>
                <div class="thinking-dots" id="thinkingDots" style="display: none;">
                    <span></span><span></span><span></span>
                </div>
            </div>
        </div>
        
        <div class="controls">
            <button id="startButton" onclick="startSession()">Start Session</button>
            <button id="stopButton" onclick="stopSession()" disabled>Stop Session</button>
            <button id="pauseButton" onclick="pauseSession()" disabled style="display: none;">⏸️ Pause</button>
            <button id="resumeButton" onclick="resumeSession()" disabled style="display: none;">▶️ Resume</button>
            <button id="resetButton" onclick="resetState()" style="display: none;">🔄 Reset</button>
            <button id="testAudioButton" onclick="testAudio()" style="background: #FF9800;">🔊 Test Audio</button>
            <button id="noiseReductionButton" onclick="toggleNoiseReduction()" style="background: #4CAF50;">🔇 Noise Filter: ON</button>
            <button id="qualityModeButton" onclick="toggleQualityMode()" style="background:#2196F3;">🎚️ Quality: HIGH</button>
        </div>
        
        <div class="controls">
            <button id="microphoneButton" onclick="toggleMicrophone()" disabled>
                🎤
            </button>
            <div id="microphoneInstructions" class="microphone-instructions">
                Click the microphone to start talking
            </div>
        
        <div class="audio-visualizer" id="visualizer" style="display: none;">
            <!-- Audio visualization bars will be added here -->
        </div>
        
        <div class="conversation-layout">
            <div class="left-pane">
                <div class="chat-container" id="chatContainer">
                    <div class="message agent-message">
                        👋 Hello! I'm your voice assistant. Start a session and click the microphone to begin talking.
                    </div>
                </div>
            </div>
            <div class="right-pane" id="agentTranscriptPane">
                <div class="agent-transcript-header">
                    <span>🗒️ Agent Transcript</span>
                    <button class="clear-transcript-btn" onclick="clearAgentTranscript()" title="Clear transcript">Clear</button>
                </div>
                <div class="agent-transcript-list" id="agentTranscriptList"></div>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let socket = null;
        let mediaRecorder = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let isRecording = false;
        let isSessionActive = false;
        let isPaused = false;
        let agentProcessing = false;
        let audioChunks = [];
        let playbackAudioContext = null;
        let audioQueue = [];
        let isPlaying = false;
        let currentAudioBuffer = null;
        let audioBufferPosition = 0;
        let audioSampleRate = 24000;
        let activeAudioSources = []; // Track active audio sources
        let audioStreamId = 0; // Unique ID for each audio stream
        let currentStreamId = 0; // Current active stream ID
        let audioChunkQueue = []; // Queue for ordered audio chunk playback
        let nextScheduledTime = 0; // Next time to schedule audio
        let currentResponseId = 0; // ID for current response
    let noiseReductionEnabled = true; // Enable noise reduction by default
    let highQualityMode = true; // High quality processing (cubic resample + de-esser)
    // New smoothing helpers
    let prevChunkTail = null; // Tail samples from previous chunk for cross-fade
    let targetSampleRate = null; // Will adopt AudioContext sample rate (often 48000) to avoid per-chunk resample artifacts
    const CROSS_FADE_MS = 6; // Cross-fade duration in milliseconds
    const MIN_LEAD_TIME = 0.18; // Seconds of lead scheduling to avoid underruns
    // Prebuffering for smoother playback
    let prebufferSeconds = 0.5; // Amount of audio to accumulate before starting playback
    let playbackStartedForCurrentResponse = false;
    let bufferedDuration = 0; // Accumulated decoded audio duration (seconds)
    let decodedChunkQueue = []; // Holds decoded AudioBuffers awaiting initial start
        
        // Initialize Socket.IO connection
        function initializeSocket() {
            socket = io();
            
            socket.on('connect', function() {
                console.log('Connected to server');
                updateStatus('Connected - Ready to start session', 'connected');
                document.getElementById('startButton').disabled = false;
            });
            
            socket.on('disconnect', function() {
                console.log('Disconnected from server');
                updateStatus('Disconnected from server', 'disconnected');
                isSessionActive = false;
                updateButtons();
            });
            
            socket.on('session_started', function(data) {
                console.log('Session started:', data);
                isSessionActive = true;
                updateStatus('Session active - Click microphone to talk', 'connected');
                updateAgentStatus('Agent Ready', false);
                document.getElementById('agentStatus').style.display = 'block';
                updateButtons();
            });
            
            socket.on('session_error', function(data) {
                console.log('Session error:', data);
                addMessage('Error: ' + data.error, 'error');
                updateStatus('Session error', 'disconnected');
            });
            
            socket.on('transcript', function(data) {
                console.log('User transcript:', data.text);
                addMessage('You said: ' + data.text, 'transcript');
                updateAgentStatus('Agent Thinking...', true);
                agentProcessing = true;
            });
            
            socket.on('agent_text', function(data) {
                console.log('Agent text:', data.text);
                addMessage(data.text, 'agent-message');
                updateAgentStatus('Agent Responding...', true);
                appendAgentTranscript(data.text, false);
            });
            
            socket.on('agent_audio_transcript', function(data) {
                console.log('Agent audio transcript:', data.text);
                addMessage('🔊 ' + data.text, 'agent-message');
                updateAgentStatus('Agent Ready', false);
                agentProcessing = false;
                appendAgentTranscript(data.text, true);
            });
            
            socket.on('audio_chunk', function(data) {
                console.log('Received audio chunk, size:', data.audio ? data.audio.length : 'no audio data');
                
                if (!data.audio) {
                    console.error('No audio data in chunk');
                    return;
                }
                
                // If this is a new response, clear previous chunks and reset timing
                if (!agentProcessing) {
                    console.log('New audio response starting - clearing previous chunks');
                    stopAllAudio();
                    audioChunkQueue = [];
                    currentResponseId = ++audioStreamId;
                    nextScheduledTime = 0;
                    // Reset prebuffer state
                    playbackStartedForCurrentResponse = false;
                    bufferedDuration = 0;
                    decodedChunkQueue = [];
                    updateAgentStatus('Agent Speaking...', true);
                    agentProcessing = true;
                }
                
                // Add chunk to queue with response ID
                audioChunkQueue.push({
                    audio: data.audio,
                    responseId: currentResponseId,
                    timestamp: Date.now()
                });
                
                // Process the queue gradually instead of all at once
                processNextAudioChunk();
            });
            
            socket.on('speech_started', function() {
                console.log('Speech started detected');
                updateStatus('Speech detected...', 'listening');
            });
            
            socket.on('speech_stopped', function() {
                console.log('Speech stopped detected');
                updateStatus('Processing...', 'processing');
            });
            
            socket.on('response_started', function() {
                console.log('Response generation started');
                updateAgentStatus('Agent Thinking...', true);
                agentProcessing = true;
                // Stop any current audio and reset for new response
                stopAllAudio();
                audioBufferPosition = playbackAudioContext ? playbackAudioContext.currentTime + 0.1 : 0.1;
            });
            
            socket.on('response_audio_done', function() {
                console.log('Audio response completed');
                updateAgentStatus('Agent Ready', false);
                agentProcessing = false;
                updateStatus('Session active - Click microphone to talk', 'connected');
            });
            
            socket.on('response_complete', function() {
                console.log('Full response completed');
                
                // If playback hasn't started yet (short response), start it now with buffered audio
                if (!playbackStartedForCurrentResponse && (decodedChunkQueue.length > 0 || audioChunkQueue.length > 0)) {
                    console.log('Response complete before playback start - forcing playback of buffered audio');
                    forceStartBufferedPlayback();
                } else if (audioChunkQueue.length > 0) {
                    console.log(`Processing ${audioChunkQueue.length} remaining audio chunks`);
                    processAudioQueue();
                }
                
                // Wait a bit then update status (give audio time to finish)
                setTimeout(() => {
                    updateAgentStatus('Agent Ready', false);
                    agentProcessing = false;
                    updateStatus('Session active - Click microphone to talk', 'connected');
                }, 500);
            });
            
            socket.on('session_paused', function(data) {
                console.log('Session paused:', data);
            });
            
            socket.on('session_resumed', function(data) {
                console.log('Session resumed:', data);
            });
            
            socket.on('api_error', function(data) {
                console.log('API error:', data);
                addMessage('API Error: ' + JSON.stringify(data.error), 'error');
                // Reset processing state on error
                agentProcessing = false;
                updateAgentStatus('Agent Ready', false);
                updateButtons();
            });
        }
        
        // Start voice session
        function startSession() {
            if (socket) {
                // Initialize audio context on user interaction (required by browsers)
                if (!playbackAudioContext) {
                    console.log('Initializing audio context on user interaction');
                    try {
                        playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                        console.log('Audio context created successfully:', playbackAudioContext.state);
                    } catch (error) {
                        console.error('Failed to create audio context:', error);
                        alert('Audio not supported in this browser');
                        return;
                    }
                }
                
                // Resume audio context if needed
                if (playbackAudioContext.state === 'suspended') {
                    console.log('Resuming audio context');
                    playbackAudioContext.resume().then(() => {
                        console.log('Audio context resumed');
                    }).catch(err => {
                        console.error('Failed to resume audio context:', err);
                    });
                }
                
                socket.emit('start_voice_session');
                updateStatus('Starting session...', 'connected');
                document.getElementById('startButton').disabled = true;
            }
        }
        
        // Stop voice session
        function stopSession() {
            if (socket) {
                socket.emit('stop_voice_session');
                isSessionActive = false;
                isPaused = false;
                updateStatus('Session stopped', 'disconnected');
                document.getElementById('agentStatus').style.display = 'none';
                if (isRecording) {
                    stopRecording();
                }
                updateButtons();
            }
        }
        
        // Pause voice session
        function pauseSession() {
            if (isSessionActive && !isPaused) {
                isPaused = true;
                if (isRecording) {
                    stopRecording();
                }
                updateStatus('Session paused', 'processing');
                updateAgentStatus('Agent Paused', false);
                updateButtons();
                
                // Notify server about pause
                if (socket) {
                    socket.emit('pause_session');
                }
            }
        }
        
        // Resume voice session
        function resumeSession() {
            if (isSessionActive && isPaused) {
                isPaused = false;
                updateStatus('Session active - Click microphone to talk', 'connected');
                updateAgentStatus('Agent Ready', false);
                updateButtons();
                
                // Notify server about resume
                if (socket) {
                    socket.emit('resume_session');
                }
            }
        }
        
        // Reset state if things get stuck
        function resetState() {
            console.log('Resetting state...');
            agentProcessing = false;
            isPlaying = false;
            
            // Stop all audio
            stopAllAudio();
            
            if (playbackAudioContext) {
                playbackAudioContext.close();
                playbackAudioContext = null;
            }
            
            if (isRecording) {
                stopRecording();
            }
            
            updateAgentStatus('Agent Ready', false);
            updateStatus('Session active - Click microphone to talk', 'connected');
            updateButtons();
            
            addMessage('🔄 State reset - Ready to continue', 'transcript');
        }
        
        // Test audio functionality
        function testAudio() {
            console.log('Testing audio...');
            
            // Initialize audio context if needed
            if (!playbackAudioContext) {
                try {
                    playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log('Audio context created for test');
                } catch (error) {
                    console.error('Failed to create audio context:', error);
                    alert('Audio not supported in this browser');
                    return;
                }
            }
            
            // Resume if suspended
            if (playbackAudioContext.state === 'suspended') {
                playbackAudioContext.resume();
            }
            
            // Create a simple test tone
            try {
                const oscillator = playbackAudioContext.createOscillator();
                const gainNode = playbackAudioContext.createGain();
                
                oscillator.connect(gainNode);
                gainNode.connect(playbackAudioContext.destination);
                
                oscillator.frequency.value = 440; // A4 note
                gainNode.gain.setValueAtTime(0, playbackAudioContext.currentTime);
                gainNode.gain.linearRampToValueAtTime(0.1, playbackAudioContext.currentTime + 0.01);
                gainNode.gain.linearRampToValueAtTime(0, playbackAudioContext.currentTime + 0.5);
                
                oscillator.start(playbackAudioContext.currentTime);
                oscillator.stop(playbackAudioContext.currentTime + 0.5);
                
                console.log('Test tone played');
                alert('If you heard a beep, audio is working!');
            } catch (error) {
                console.error('Test audio failed:', error);
                alert('Audio test failed: ' + error.message);
            }
        }
        
        // Toggle noise reduction
        function toggleNoiseReduction() {
            noiseReductionEnabled = !noiseReductionEnabled;
            const button = document.getElementById('noiseReductionButton');
            
            if (noiseReductionEnabled) {
                button.textContent = '🔇 Noise Filter: ON';
                button.style.background = '#4CAF50';
                console.log('Noise reduction enabled');
            } else {
                button.textContent = '🔊 Noise Filter: OFF';
                button.style.background = '#FF5722';
                console.log('Noise reduction disabled');
            }
        }

        // Toggle quality mode (between high fidelity and low latency)
        function toggleQualityMode() {
            highQualityMode = !highQualityMode;
            const btn = document.getElementById('qualityModeButton');
            if (highQualityMode) {
                btn.textContent = '🎚️ Quality: HIGH';
                btn.style.background = '#2196F3';
                prebufferSeconds = Math.max(prebufferSeconds, 0.45);
            } else {
                btn.textContent = '⚡ Quality: LOW';
                btn.style.background = '#9E9E9E';
                prebufferSeconds = 0.25;
            }
            console.log('Quality mode switched to', highQualityMode ? 'HIGH' : 'LOW');
        }
        
        // Toggle microphone recording
        async function toggleMicrophone() {
            if (!isSessionActive || isPaused) return;
            
            if (isRecording) {
                stopRecording();
            } else {
                await startRecording();
            }
        }
        
        // Start audio recording
        async function startRecording() {
            try {
                // Stop any currently playing audio before starting recording
                stopAllAudio();
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                // Set up audio context for processing
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                const source = audioContext.createMediaStreamSource(stream);
                
                // Create a script processor for real-time audio processing
                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                processor.onaudioprocess = function(event) {
                    if (!isRecording) return;
                    
                    const inputBuffer = event.inputBuffer;
                    const inputData = inputBuffer.getChannelData(0);
                    
                    // Convert float32 to int16 PCM
                    const pcmData = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        const sample = Math.max(-1, Math.min(1, inputData[i]));
                        pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
                    }
                    
                    // Convert to base64 and send
                    const base64Audio = btoa(String.fromCharCode(...new Uint8Array(pcmData.buffer)));
                    if (socket && isRecording) {
                        socket.emit('audio_data', { audio: base64Audio });
                    }
                };
                
                source.connect(processor);
                processor.connect(audioContext.destination);
                
                // Set up audio visualization
                analyser = audioContext.createAnalyser();
                source.connect(analyser);
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                visualizeAudio(dataArray);
                
                isRecording = true;
                updateButtons();
                updateStatus('Recording... Speak now!', 'listening');
                
                // Store references for cleanup
                window.currentStream = stream;
                window.currentProcessor = processor;
                
            } catch (error) {
                console.error('Error starting recording:', error);
                addMessage('Error accessing microphone: ' + error.message, 'error');
            }
        }
        
        // Stop audio recording
        function stopRecording() {
            if (isRecording) {
                isRecording = false;
                
                // Clean up audio processing
                if (window.currentProcessor) {
                    window.currentProcessor.disconnect();
                    window.currentProcessor = null;
                }
                
                if (window.currentStream) {
                    window.currentStream.getTracks().forEach(track => track.stop());
                    window.currentStream = null;
                }
                
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                
                updateButtons();
                updateStatus('Processing your speech...', 'connected');
                
                // Stop visualization
                document.getElementById('visualizer').style.display = 'none';
                
                // Trigger response from the AI agent
                if (socket && isSessionActive) {
                    console.log('Triggering AI response...');
                    socket.emit('trigger_response');
                }
            }
        }
        
        // Visualize audio input
        function visualizeAudio(dataArray) {
            if (!isRecording) return;
            
            analyser.getByteFrequencyData(dataArray);
            
            const visualizer = document.getElementById('visualizer');
            visualizer.style.display = 'flex';
            visualizer.innerHTML = '';
            
            for (let i = 0; i < 32; i++) {
                const bar = document.createElement('div');
                bar.className = 'visualizer-bar';
                const height = (dataArray[i] / 255) * 50 + 5;
                bar.style.height = height + 'px';
                visualizer.appendChild(bar);
            }
            
            requestAnimationFrame(() => visualizeAudio(dataArray));
        }
        
        // Play audio chunk received from server
        // Stop all currently playing audio
        function stopAllAudio() {
            console.log('Stopping all audio sources');
            
            // Stop all active audio sources immediately
            activeAudioSources.forEach(source => {
                try {
                    source.stop(0); // Stop immediately
                } catch (e) {
                    console.log('Source already stopped or error stopping:', e);
                }
            });
            activeAudioSources = [];
            
            // Clear audio queues
            audioQueue = [];
            audioChunkQueue = [];
            isPlaying = false;
            
            // Reset timing
            nextScheduledTime = 0;
            playbackStartedForCurrentResponse = false;
            bufferedDuration = 0;
            decodedChunkQueue = [];
            
            console.log('All audio stopped, queues cleared');
        }

        async function processNextAudioChunk() {
            if (audioChunkQueue.length === 0) return;
            
            // Don't play if paused
            if (isPaused) {
                console.log('Session paused, not processing audio chunk');
                return;
            }
            
            // Initialize audio context if needed
            if (!playbackAudioContext) {
                try {
                    playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log('Audio context created for chunk processing');
                } catch (error) {
                    console.error('Failed to create audio context:', error);
                    return;
                }
            }
            
            // Resume if suspended
            if (playbackAudioContext.state === 'suspended') {
                await playbackAudioContext.resume();
            }
            
            // Set initial timing if needed
            if (nextScheduledTime === 0) {
                nextScheduledTime = playbackAudioContext.currentTime + 0.3; // Longer initial delay
            }
            
            // Process one chunk at a time
            const chunk = audioChunkQueue.shift();
            
            // Skip if this chunk is from an old response
            if (chunk.responseId !== currentResponseId) {
                console.log('Skipping chunk from old response');
                // Process next chunk
                if (audioChunkQueue.length > 0) {
                    setTimeout(() => processNextAudioChunk(), 10);
                }
                return;
            }
            
            try {
                const audioBuffer = await createAudioBufferFromChunk(chunk.audio);
                if (audioBuffer) {
                    if (!playbackStartedForCurrentResponse) {
                        // Buffer until we have enough duration
                        decodedChunkQueue.push(audioBuffer);
                        bufferedDuration += audioBuffer.duration;
                        console.log(`Buffered chunk (${audioBuffer.duration.toFixed(3)}s). Total buffered: ${bufferedDuration.toFixed(3)}s / target ${prebufferSeconds}s`);
                        if (bufferedDuration >= prebufferSeconds) {
                            console.log('Prebuffer threshold reached - starting playback');
                            startBufferedPlayback();
                        }
                    } else {
                        // Playback already started - schedule immediately in sequence
                        const currentTime = playbackAudioContext.currentTime;
                        if (nextScheduledTime < currentTime + 0.02) {
                            nextScheduledTime = currentTime + 0.05; // catch up if fell behind
                        }
                        scheduleAudioBuffer(audioBuffer, nextScheduledTime);
                        nextScheduledTime += audioBuffer.duration; // no artificial gap when using cross-fade
                    }
                }
            } catch (error) {
                console.error('Error processing audio chunk:', error);
            }
            
            // Process next chunk after a small delay
            if (audioChunkQueue.length > 0) {
                setTimeout(() => processNextAudioChunk(), 20);
            }
        }

        async function processAudioQueue() {
            if (audioChunkQueue.length === 0) return;
            
            // Don't play if paused
            if (isPaused) {
                console.log('Session paused, not processing audio queue');
                return;
            }
            
            // Initialize audio context if needed
            if (!playbackAudioContext) {
                try {
                    playbackAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                    console.log('Audio context created for queue processing');
                } catch (error) {
                    console.error('Failed to create audio context:', error);
                    return;
                }
            }
            
            // Resume if suspended
            if (playbackAudioContext.state === 'suspended') {
                await playbackAudioContext.resume();
            }
            
            // Set initial timing if needed
            if (nextScheduledTime === 0) {
                nextScheduledTime = playbackAudioContext.currentTime + 0.2; // Larger initial delay
            }
            
            // Process all queued chunks
            while (audioChunkQueue.length > 0) {
                const chunk = audioChunkQueue.shift();
                
                // Skip if this chunk is from an old response
                if (chunk.responseId !== currentResponseId) {
                    console.log('Skipping chunk from old response');
                    continue;
                }
                
                try {
                    const audioBuffer = await createAudioBufferFromChunk(chunk.audio);
                    if (audioBuffer) {
                        if (!playbackStartedForCurrentResponse) {
                            decodedChunkQueue.push(audioBuffer);
                            bufferedDuration += audioBuffer.duration;
                        } else {
                            scheduleAudioBuffer(audioBuffer, nextScheduledTime);
                            nextScheduledTime += audioBuffer.duration;
                        }
                        console.log(`Scheduled chunk duration: ${audioBuffer.duration}s, next start: ${nextScheduledTime}`);
                    }
                } catch (error) {
                    console.error('Error processing audio chunk:', error);
                }
            }

            if (!playbackStartedForCurrentResponse && decodedChunkQueue.length > 0) {
                console.log('Starting playback after processing full queue (response complete)');
                startBufferedPlayback();
            }
        }

        function startBufferedPlayback() {
            if (decodedChunkQueue.length === 0) return;
            playbackStartedForCurrentResponse = true;
            if (!playbackAudioContext) return;
            if (nextScheduledTime === 0) {
                nextScheduledTime = playbackAudioContext.currentTime + 0.25; // initial lead
            }
            console.log(`Starting buffered playback with ${decodedChunkQueue.length} chunks totaling ${bufferedDuration.toFixed(3)}s`);
            while (decodedChunkQueue.length > 0) {
                const buf = decodedChunkQueue.shift();
                scheduleAudioBuffer(buf, nextScheduledTime);
                nextScheduledTime += buf.duration; // contiguous scheduling
            }
        }

        function forceStartBufferedPlayback() {
            // Use when response completes before threshold
            if (playbackStartedForCurrentResponse) return;
            if (decodedChunkQueue.length === 0) return;
            console.log('Force starting playback (short response)');
            startBufferedPlayback();
        }

        async function createAudioBufferFromChunk(base64Audio) {
            try {
                // 1. Decode base64 -> bytes
                const binaryString = atob(base64Audio);
                const bytes = new Uint8Array(binaryString.length);
                for (let i = 0; i < binaryString.length; i++) bytes[i] = binaryString.charCodeAt(i);

                // 2. Int16 PCM (24kHz mono)
                const pcm16 = new Int16Array(bytes.buffer);
                if (pcm16.length === 0) return null;

                // 3. Ensure target sample rate matches AudioContext (prevents per-chunk resample clicks)
                if (!targetSampleRate) targetSampleRate = playbackAudioContext.sampleRate; // usually 44100 or 48000
                const srcRate = audioSampleRate; // 24000
                let floatData = new Float32Array(pcm16.length);
                for (let i = 0; i < pcm16.length; i++) floatData[i] = Math.max(-1, Math.min(1, pcm16[i] / 32768));

                // 4. Optional light denoise (remove DC & very low amplitude hiss without gating)
                let mean = 0;
                for (let v of floatData) mean += v; mean /= floatData.length;
                for (let i = 0; i < floatData.length; i++) floatData[i] -= mean; // DC offset removal

                // Soft expander (NOT hard gate) to avoid clicks: y = x * (|x|/thr)^alpha for |x|<thr
                const thr = 0.012; // ~ -38dBFS
                const alpha = 0.6;
                for (let i = 0; i < floatData.length; i++) {
                    const x = floatData[i];
                    const ax = Math.abs(x);
                    if (ax < thr) {
                        const scale = Math.pow(ax / thr, alpha);
                        floatData[i] = x * scale; // smoothly push toward 0
                    }
                }

                // 5. Resample (cubic Hermite in HQ mode; linear otherwise)
                let resampled;
                if (srcRate !== targetSampleRate) {
                    const ratio = targetSampleRate / srcRate;
                    const newLen = Math.round(floatData.length * ratio);
                    resampled = new Float32Array(newLen);
                    if (highQualityMode) {
                        for (let i = 0; i < newLen; i++) {
                            const srcPos = i / ratio;
                            const i1 = Math.floor(srcPos);
                            const t = srcPos - i1;
                            const i0 = i1 - 1;
                            const i2 = i1 + 1;
                            const i3 = i1 + 2;
                            const y0 = floatData[i0] !== undefined ? floatData[i0] : floatData[i1] || 0;
                            const y1 = floatData[i1] !== undefined ? floatData[i1] : y0;
                            const y2 = floatData[i2] !== undefined ? floatData[i2] : y1;
                            const y3 = floatData[i3] !== undefined ? floatData[i3] : y2;
                            const t2 = t * t; const t3 = t2 * t;
                            const a = -0.5*y0 + 1.5*y1 - 1.5*y2 + 0.5*y3;
                            const b = y0 - 2.5*y1 + 2*y2 - 0.5*y3;
                            const c = -0.5*y0 + 0.5*y2;
                            const d = y1;
                            let sample = a*t3 + b*t2 + c*t + d;
                            sample += (Math.random() + Math.random() - 1) * 1e-5; // mild dithering
                            resampled[i] = Math.max(-1, Math.min(1, sample));
                        }
                    } else {
                        for (let i = 0; i < newLen; i++) {
                            const srcPos = i / ratio;
                            const i0 = Math.floor(srcPos);
                            const frac = srcPos - i0;
                            const s0 = floatData[i0] || 0;
                            const s1 = floatData[i0 + 1] || s0;
                            resampled[i] = s0 + (s1 - s0) * frac;
                        }
                    }
                } else {
                    resampled = floatData;
                }

                // 5b. Dynamic de-esser (HQ only)
                if (highQualityMode) {
                    let lp = 0;
                    const alpha = Math.min(0.25, 5000 / targetSampleRate); // ~5kHz one-pole LP
                    for (let i = 0; i < resampled.length; i++) {
                        const x = resampled[i];
                        lp += alpha * (x - lp);
                        const hi = x - lp;
                        const ahi = Math.abs(hi);
                        if (ahi > 0.12) {
                            const reduce = Math.min(0.45, (ahi - 0.12) * 1.8);
                            resampled[i] = x - hi * reduce;
                        }
                    }
                }

                // 6. Cross-fade with previous chunk tail to remove discontinuity clicks
                const fadeSamples = Math.min(
                    Math.floor((CROSS_FADE_MS / 1000) * targetSampleRate),
                    Math.floor(resampled.length / 4)
                );

                if (prevChunkTail && fadeSamples > 8) {
                    const tailLen = Math.min(prevChunkTail.length, fadeSamples);
                    for (let i = 0; i < tailLen; i++) {
                        const fadeIn = (i + 1) / tailLen; // new chunk fade in
                        const fadeOut = 1 - fadeIn;       // previous tail fade out
                        const mixed = prevChunkTail[prevChunkTail.length - tailLen + i] * fadeOut + resampled[i] * fadeIn;
                        resampled[i] = mixed;
                    }
                }

                // 7. Store new tail
                const tailStoreLen = Math.min(fadeSamples * 2, resampled.length);
                prevChunkTail = resampled.slice(resampled.length - tailStoreLen);

                // 8. Gentle overall fade edges (very short) to eliminate micro-clicks at capture boundaries
                const edgeFade = Math.min(16, Math.floor(resampled.length / 50));
                for (let i = 0; i < edgeFade; i++) {
                    const w = i / edgeFade;
                    resampled[i] *= w;
                    resampled[resampled.length - 1 - i] *= w;
                }

                // 9. Create final AudioBuffer in target sample rate
                const audioBuffer = playbackAudioContext.createBuffer(1, resampled.length, targetSampleRate);
                audioBuffer.copyToChannel(resampled, 0);
                return audioBuffer;
            } catch (e) {
                console.error('createAudioBufferFromChunk error', e);
                return null;
            }
        }

        function scheduleAudioBuffer(audioBuffer, requestedStart) {
            try {
                // Maintain a minimum lead time to reduce underrun pops
                const now = playbackAudioContext.currentTime;
                let startTime = Math.max(requestedStart, now + MIN_LEAD_TIME);

                const source = playbackAudioContext.createBufferSource();
                source.buffer = audioBuffer;
                activeAudioSources.push(source);

                // Light processing chain (avoid heavy filtering that can introduce phase clicks)
                const hpf = playbackAudioContext.createBiquadFilter();
                hpf.type = 'highpass';
                hpf.frequency.value = 65; // remove ultra low rumble

                const lpf = playbackAudioContext.createBiquadFilter();
                lpf.type = 'lowpass';
                lpf.frequency.value = highQualityMode ? 12000 : 7800; // wider band in HQ mode

                const comp = playbackAudioContext.createDynamicsCompressor();
                comp.threshold.value = -28;
                comp.knee.value = 18;
                comp.ratio.value = 3;
                comp.attack.value = 0.006;
                comp.release.value = 0.18;

                const gain = playbackAudioContext.createGain();
                gain.gain.value = noiseReductionEnabled ? 0.9 : 1.0;

                if (noiseReductionEnabled) {
                    source.connect(hpf); hpf.connect(lpf); lpf.connect(comp); comp.connect(gain); gain.connect(playbackAudioContext.destination);
                } else {
                    source.connect(gain); gain.connect(playbackAudioContext.destination);
                }

                source.start(startTime);
                source.onended = () => {
                    const idx = activeAudioSources.indexOf(source);
                    if (idx > -1) activeAudioSources.splice(idx, 1);
                    try { source.disconnect(); hpf.disconnect(); lpf.disconnect(); comp.disconnect(); gain.disconnect(); } catch (_) {}
                };
            } catch (e) {
                console.error('scheduleAudioBuffer error', e);
            }
        }
        
        // Old playAudioChunk and playAudioBufferImmediate functions removed
        // Now using processAudioQueue system for proper chunk sequencing
        
        function playNextAudioChunk() {
            // This function is now simplified since we use immediate playback
            // Keep it for compatibility but most logic moved to playAudioBufferImmediate
            if (audioQueue.length === 0) {
                isPlaying = false;
                agentProcessing = false;
                updateAgentStatus('Agent Ready', false);
                return;
            }
            
            // Check if audio context is still valid
            if (!playbackAudioContext || playbackAudioContext.state === 'closed') {
                console.log('Audio context invalid, clearing queue');
                audioQueue = [];
                isPlaying = false;
                agentProcessing = false;
                updateAgentStatus('Agent Ready', false);
                return;
            }
            
            try {
                isPlaying = true;
                const audioBuffer = audioQueue.shift();
                playAudioBufferImmediate(audioBuffer);
                
                // Continue with next chunk
                setTimeout(() => playNextAudioChunk(), 10);
                
            } catch (error) {
                console.error('Error in playNextAudioChunk:', error);
                // Continue with next chunk despite error
                setTimeout(() => playNextAudioChunk(), 100);
            }
        }
        
        // Update status display
        function updateStatus(message, className) {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = 'status ' + className;
        }
        
        // Update agent status display
        function updateAgentStatus(message, isThinking) {
            const agentStatusText = document.getElementById('agentStatusText');
            const thinkingDots = document.getElementById('thinkingDots');
            const agentStatus = document.getElementById('agentStatus');
            
            agentStatusText.textContent = message;
            
            if (isThinking) {
                thinkingDots.style.display = 'inline-flex';
                agentStatus.className = 'agent-status thinking';
            } else {
                thinkingDots.style.display = 'none';
                agentStatus.className = 'agent-status';
            }
        }
        
        // Update button states
        function updateButtons() {
            const startBtn = document.getElementById('startButton');
            const stopBtn = document.getElementById('stopButton');
            const pauseBtn = document.getElementById('pauseButton');
            const resumeBtn = document.getElementById('resumeButton');
            const resetBtn = document.getElementById('resetButton');
            const micBtn = document.getElementById('microphoneButton');
            const instructions = document.getElementById('microphoneInstructions');
            
            startBtn.disabled = isSessionActive;
            stopBtn.disabled = !isSessionActive;
            
            // Microphone button logic
            const micDisabled = !isSessionActive || isPaused || agentProcessing;
            micBtn.disabled = micDisabled;
            
            if (isSessionActive) {
                pauseBtn.style.display = isPaused ? 'none' : 'inline-block';
                resumeBtn.style.display = isPaused ? 'inline-block' : 'none';
                resetBtn.style.display = 'inline-block';
                pauseBtn.disabled = false;
                resumeBtn.disabled = false;
                resetBtn.disabled = false;
            } else {
                pauseBtn.style.display = 'none';
                resumeBtn.style.display = 'none';
                resetBtn.style.display = 'none';
            }
            
            // Update microphone button and instructions
            if (isRecording) {
                micBtn.className = 'recording';
                micBtn.textContent = '🔴';
                instructions.textContent = 'Recording... Click to stop';
            } else if (!isSessionActive) {
                micBtn.className = '';
                micBtn.textContent = '🎤';
                instructions.textContent = 'Start a session first';
            } else if (isPaused) {
                micBtn.className = 'disabled';
                micBtn.textContent = '⏸️';
                instructions.textContent = 'Session paused - Resume to continue';
            } else if (agentProcessing) {
                micBtn.className = 'disabled';
                micBtn.textContent = '🤖';
                instructions.textContent = 'Agent is responding... Please wait';
            } else {
                micBtn.className = '';
                micBtn.textContent = '🎤';
                instructions.textContent = 'Click to start talking';
            }
        }
        
        // Add message to chat
        function addMessage(text, className) {
            const chatContainer = document.getElementById('chatContainer');
            const message = document.createElement('div');
            message.className = 'message ' + className;
            message.textContent = text;
            chatContainer.appendChild(message);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function appendAgentTranscript(text, isAudio) {
            if (!text) return;
            const list = document.getElementById('agentTranscriptList');
            if (!list) return;
            const line = document.createElement('div');
            line.className = 'agent-line';
            const ts = new Date();
            const timeStr = ts.toLocaleTimeString([], {hour: '2-digit', minute: '2-digit', second: '2-digit'});
            line.innerHTML = `${isAudio ? '🔊' : '💬'} ${escapeHtml(text)}<time>${timeStr}</time>`;
            list.appendChild(line);
            list.scrollTop = list.scrollHeight;
        }

        function clearAgentTranscript() {
            const list = document.getElementById('agentTranscriptList');
            if (list) list.innerHTML = '';
        }

        function escapeHtml(str) {
            return str.replace(/[&<>"']/g, function(c){
                return ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;','\'':'&#39;'}[c]);
            });
        }
        
        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', function() {
            initializeSocket();
            updateButtons();
            
            // Add keyboard shortcuts
            document.addEventListener('keydown', function(event) {
                if (event.code === 'Space' && !isRecording) {
                    event.preventDefault();
                    if (isSessionActive && !isPaused && !agentProcessing) {
                        toggleMicrophone();
                    }
                } else if (event.code === 'KeyP' && event.ctrlKey) {
                    event.preventDefault();
                    if (isSessionActive) {
                        if (isPaused) {
                            resumeSession();
                        } else {
                            pauseSession();
                        }
                    }
                }
            });
        });
    </script>
</body>
</html>
